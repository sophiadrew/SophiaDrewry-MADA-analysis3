---
title: "Analysis3"
author: "Sophia Drewry"
date: "11/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This script loads the cleaned and processed data to perform some formal statistical fitting
This excersise will focus on the continuous outcome "BodyTemp"
```{r}
# load needed packages. make sure they are installed or else...
library(dplyr) #for data processing
library(here) #to set paths
library(tidymodels) #to fit models
library(rpart)
library(glmnet)
library(ranger)
library(future)
library(parallel)
library(doParallel)
```
#Load data
```{r}
# note the use of the here() package and not absolute paths
dataSPOT <- here::here("data","processed_data","processeddta.rds")
# load data. 
processeddta <-readRDS(dataSPOT)
```
# Data splitting
Here we are going to split the data randomly into training and testing subsets
- Training data will be used to fit the model. 
- Testing set will be used to evaluate the model.
```{r}
# Setting a seed for random number generation so if this analysis is reproduced, the same random set will be generated
set.seed(123)
# Subsetting 70% of data into training and 20% of data into testing
# We using Body Temp to stratify
data_split <- initial_split(processeddta, prop = .7, strata = "BodyTemp")
# Creating training data
train_data <- training(data_split)
# Creating testing data
test_data  <- testing(data_split)
```
# 5-fold cross-validation, 5x repeated
```{r}
# Creating a resample object for our trainng data
set.seed(123)
folds <- vfold_cv(train_data, v = 5, repeats = 5, strata = "BodyTemp")
folds
```
///////////////////////////////////////////////////////////////////////////////
## Setting workflows & training models: Model 1 
Setting up lr.mod that will be used for the rest of the excersise
```{r}
lr.mod <- linear_reg() %>% 
  set_engine("lm") %>%
  set_mode("regression")
```

# Fitting a linear model to BodyTemp 
```{r}
#########################  Dummy Var #########################
# Creating Recipe TRAIN DTA for all categorical Dummy Variables
#Setting up the linear model
D.BodyTemp.rec <- recipe(BodyTemp ~ ., data = train_data)  %>% 
  step_dummy(all_nominal(), -BodyTemp)
# Create workflow
D.BT.wflow <- workflow() %>% 
  add_model(lr.mod) %>% 
  add_recipe(BodyTemp.rec)
# Fit model to training data
D.BT.fit <- 
  D.BT.wflow %>% 
  fit(data = train_data)
# evaluate
D.BT.fit %>% 
  extract_fit_parsnip() %>% 
  tidy()
```

# Creating a Null Model 
This is to use as a comparison for our other future models
```{r}
# Create null formula
BodyTemp.rec <- recipe(BodyTemp ~ 1., data = train_data)  
```

#########################  Null Training    #########################
```{r}
# Creating null recipe & model with TRAIN data
# set workflow
N.BT.train.wflow <-
  workflow() %>% 
  add_model(lr.mod) %>% 
  add_recipe(BodyTemp.rec)
# fitting
N.BT.train.fit <- 
  N.BT.train.wflow %>% 
  fit(data = train_data)
# usual
N.BT.train.fit %>% 
  extract_fit_parsnip() %>% 
  tidy()
# RMSE
predict(N.BT.train.fit, train_data)
N.BT.train.aug <- augment(N.BT.train.fit, train_data)
N.BT.train.aug %>% select(BodyTemp, .pred) 
N.BT.train.aug %>% rmse(truth = BodyTemp, .pred)

# RMSE = 1.209327	
```
  
################################ Null  Testing   ################################
```{r}
# fitting
N.BT.train.fit <- 
  N.BT.train.wflow %>% 
  fit(data = train_data)
predict(N.BT.train.fit, test_data)
N.BT.train.aug <- augment(N.BT.train.fit, test_data) # I dont think i need this
N.BT.train.aug %>% select(BodyTemp, .pred) 
N.BT.train.aug %>% #taking the root-mean square error of the model
  rmse(truth = BodyTemp, .pred)
# RMSE = 1.163343	

```
///////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////
# Creating Models
################################   Tree  ################################
```{r}
#cross validation
set.seed(123)
other_folds <- vfold_cv(train_data)
# Note, this was included in the tidymodels tutorial but it is not needed since we already created our own CV data. I am keepin git here because if I dont use it in LASSO model it will crash. Not sure why.

## Tuning hyperparameters
tune_spec <- 
  decision_tree(cost_complexity = tune(), 
  tree_depth = tune()) %>% 
  set_engine("rpart") %>% 
  set_mode("regression")
tune_spec # We will come back to these parameters
# setting workflow
treeBT <- workflow() %>%
  add_model(tune_spec) %>%
  add_recipe(D.BodyTemp.rec)

```
## Tuning with a grid
```{r}
# Create a grid
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5)
# tuning
tree_res <- treeBT %>% 
  tune_grid(resamples = folds, grid = tree_grid)
tree_res %>% collect_metrics()

```
## Plotting for the world to see
```{r}
tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)
# Looks like we have 2 deeper "trees" that perform similar in cost complexity as well, but not the best
# Lets check out the top 5
tree_res %>% show_best("rmse")
# Now to pull out the best set of hyperparameter values for our decision tree model
best_tree <- tree_res %>% select_best("rmse")
# finalize workflow
final_wf <- treeBT %>% finalize_workflow(best_tree)
# final fit
final_fit <- final_wf %>% fit(data = train_data) 
final_fit
final_pred <- predict(final_fit, train_data)
tree_res %>% show_best("rmse", n = 1)
# RMSE = 1.193128	
```
RMSE = 1.193128	compared to Null model RMSE = 1.209 is not much of a difference

## Visualize
```{r}
rpart.plot(extract_fit_parsnip(final_fit)$fit)
# simple one liner code used from Dr. Handel
```
################################   LASSO  ################################
sources:
https://www.tidymodels.org/start/case-study/
https://stackoverflow.com/questions/66639452/tuning-a-lasso-model-and-predicting-using-tidymodels

## Building model
```{r}
# set workflow
lasso.mod <- linear_reg(mode = "regression", penalty = tune(), mixture = 1) %>% 
   set_engine("glmnet")
lasso.wflow <- workflow() %>%
    add_model(lasso.mod) %>%
    add_recipe(D.BodyTemp.rec)
```
## Train and tune LASSO
### Setting cores
This code was taken from Dr. Handel, prevents my my session from aborting
```{r}
cores <- parallel::detectCores()
cores
ncores = 4
cl <- makePSOCKcluster(ncores)
registerDoParallel(cl)

# creating grid and tuning
lr_reg_grid <- tibble(penalty = 10^seq(-3, 0, length.out = 30)) 

# tuning on training data
lasso.res <- lasso.wflow %>% 
  tune_grid(resamples = other_folds,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse))
# turn off parallel cluster
stopCluster(cl)

```
Well, R session keeps aborting. I am stayin ghopeful. Here is the code if it were to work
## Choosing the best performing model
```{r}
lasso.top.models <- lasso.res %>% 
  show_best("rmse") 
lasso.best <- lasso.res %>% 
  collect_metrics() 
lasso.best
# finalize workflow with the best model
best.lasso.wflow <- lasso.wflow %>% 
  finalize_workflow(lasso.top.models)
# fitting best performing model
best.lasso.fit <- best.lasso.wflow %>% 
  fit(data = train_data)
lasso.pred <- predict(best.lasso.fit, train_data)
```
## Plotting performance
This code is borrowed from Dr. Handel
```{r}
x <- best_lasso_fit$fit$fit$fit
plot(x, "lambda")
```

################################   Random Forrest  ################################
sources:
https://www.tidymodels.org/start/case-study/
https://stackoverflow.com/questions/65370000/tidymodels-a-plot-showing-performance-model-metrics-rmse-rsq-for-a-random-f
```{r}
# query the number of cores on my own computer
cores <- parallel::detectCores()
cores

# Create model
rf.mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_engine("ranger", num.threads = cores) %>% 
  set_mode("regression")
```
## Create recipe and workflow
```{r}
rf.wflow <- 
  workflow() %>% 
  add_model(rf.mod) %>% 
  add_recipe(D.BodyTemp.rec)
```
# Train and tune
```{r}
# prevent R from crashing
ncores = 4
cl <- makePSOCKcluster(ncores)
registerDoParallel(cl)

# tuning grid. Code from Dr. Handel
rf.grid  <- expand.grid(mtry = c(3, 4, 5, 6), min_n = c(40,50,60), trees = c(500,1000))

# space-filling design to tune, with 25 candidate models
set.seed(123)
rf.res <- rf.wflow %>% 
  tune_grid(resamples = folds, 
            grid = rf.grid,
            metrics = metric_set(rmse))
# R keeps aborting session...
# turn off parallel cluster
stopCluster(cl)
```
## Evaluation
```{r}
rf_res %>% show_best(metric = "rmse")
autoplot(rf_res)

rf_best <- rf_res %>% 
  select_best(metric = "rmse")
rf_best

rf_res %>% 
  collect_predictions()
```

# Final model. 
Since the other two models are not working, I am going to run the final model on the Trees model
```{r}
# use test data
final.mod <- final_wf %>% last_fit(test_split) # using test data
final.mod %>% collect_metrics()


# residuals
final.res <- final_fit %>%
  augment() %>% 
  select(.pred, BodyTemp) %>%
  mutate(.resid = BodyTemp - .pred)

# training vs truth
final.pred <- ggplot(final.res, aes(x = BodyTemp, y = .pred)) + 
  geom_point()
final_pred_plot

# residuals vs trth
final_resid_plot <- ggplot(final_resid, aes(y = .resid, x = .pred)) + 
  geom_point() 
final_resid_plot 

#compare to null model

```